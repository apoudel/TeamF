# -their age
# -their average "beauty" rating
load(url("http://www.openintro.org/stat/data/evals.RData"))
evals <- evals %>%
tbl_df() %>%
select(score, ethnicity, gender, language, age, bty_avg, rank)
View(evals)
# Beauty average? For real? Apparently so:
# 1. The red line is the mean teaching score by itself (using no other information
# about the teachers)
# 2. The blue is the the mean teaching score controlling for beauty. There is
# a significant non-zero (in fact positive) slope.
# i.e. holding all other variables constant, there appears to be a positive
# correlation betwewn beauty score and teaching score. Is it causal? We can't
# say with the info we have.
ggplot(evals, aes(x=bty_avg, y=score)) +
geom_jitter() +
geom_hline(yintercept=mean(evals$score), col="red", size=1) +
geom_smooth(method="lm") +
labs(x="Beauty Score", y="Teaching Score")
# We must first convert all our categorical variables to numerical ones. We use
# the match() function to have the specified coding of the levels of the
# categorical variables.
evals <- evals %>%
mutate(
# Rank: 0 = teaching, 1 = tenure track, 2 = tenure
rank = match(rank, c("teaching", "tenure track", "tenured")) - 1,
# Ethnicity: 0 = non-minority, 1 = minority
ethnicity = match(ethnicity, c("not minority", "minority")) - 1,
# Gender: 0 = male, 1 = female
gender = match(gender, c("male", "female")) - 1,
# Language: 0 = native english speaker, 1 = non-native english speaker
language = match(language, c("english", "non-english")) - 1
)
# Fit CART model ----------------------------------------------------------
# The "depth of tree" is among the many knobs we can control.
knobs <- rpart.control(maxdepth = 3)
# Run the following to see other knobs and stopping criteria
?rpart.control
# We fit the CART model:
model_formula <- as.formula("score ~ ethnicity + gender + language + age + bty_avg + rank")
model_CART <- rpart(model_formula, data = evals, control=knobs)
# Let's study the output:
print(model_CART)
summary(model_CART)
# Blech... Hideous. broom package to the...
broom::tidy(model_CART)
broom::augment(model_CART)
broom::glance(model_CART)
plot(model_CART, margin=0.25)
text(model_CART, use.n = TRUE)
box()
evals %>%
filter(bty_avg >= 2.167) %>%
filter(gender >= 0.5) %>%
group_by(old = age >= 34.5) %>%
summarise(count=n(), mean_eval=mean(score))
predict(model_CART)
evals %>%
sample_n(20) %>%
predict(model_CART, newdata=.)
evals %>%
filter(bty_avg >= 2.167) %>%
filter(gender >= 0.5) %>%
group_by(old = age >= 34.5) %>%
summarise(count=n(), mean_eval=mean(score))
knobs_2 <- rpart.control(maxdepth = 5)
model_CART_2 <- rpart(model_formula, data = evals, control=knobs_2)
# Note: This is base R facetting:
par(mfrow=c(1, 2))
plot(model_CART, margin=0.25)
text(model_CART, use.n = TRUE)
box()
plot(model_CART_2, margin=0.25)
text(model_CART_2, use.n = TRUE)
box()
install("USAboundaries")
package("USAboundaries")
install.packages("USAboundaries")
library(tidyverse)
library(USAboundaries)
library(sp)
library(stringr)
library(broom)
# Load Counties Data -----------------------------------------------------------
# Data consists of observations for 3109 counties in 2000 election
# -(longitude, latitude) of county's centroid i.e. middle point
# -area_sqmi: surface area of county in square miles
# -bush/gore: number of votes for George W. Bush/Al Gore. Other candidates dropped for simplicity.
# -n=bush+gore. NOT the # of votes, but # for Bush + # for Gore
# -pop_density is not true (# of people)/area, but (# of Bush/Gore voters)/area.
elections_county <-
"https://raw.githubusercontent.com/rudeboybert/MATH218/gh-pages/assets/kMeans/elections_2000.csv" %>%
read_csv() %>%
mutate(pop_density = n/area_sqmi)
View(elections_county)
counties_map <- USAboundaries::us_counties("2000-11-01")
states_map <- USAboundaries::us_states("2000-11-01")
plot(counties_map, axes=TRUE)
plot(states_map, axes=TRUE)
# Let's plot in ggplot. broom::tidy() to the rescue!
counties_map_tidy <- counties_map %>%
# set id variable to be FIPS codes
tidy(region="fips") %>%
tbl_df() %>%
# Remove Alaska/Hawaii, who have FIPS codes 02 & 15
filter(!str_sub(id, 1, 2) %in% c("02", "15"))
states_map_tidy <- states_map %>%
tidy(region="abbr_name") %>%
tbl_df() %>%
# Remove Alaska/Hawaii
filter(!id %in% c("AK", "HI"))
ggplot(NULL, aes(x=long, y=lat)) +
# The group aesthetic ensures points in the same polygon are kept together:
geom_polygon(data=counties_map_tidy, aes(group=group), fill="white") +
# Trace outlines of counties then states:
geom_path(data=counties_map_tidy, aes(group=group), col="black", size=0.05) +
geom_path(data=states_map_tidy, aes(group=group), col="black", size=0.3) +
# Use correct aspect ratio for maps:
coord_map()
# Plot 2000 Electoral Map -----------------------------------------------------------
# Overall the lower 48 George W. Bush got 49.7% of vote
overall_bush_prop <- sum(elections_county$bush)/sum(elections_county$n)
elections_map <- counties_map_tidy %>%
inner_join(elections_county, by=c("id"="fips"))
ggplot(NULL, aes(x=long, y=lat)) +
# Fill in county polygons color-coded by %'age margin for push over 49.7%
geom_polygon(data=elections_map, aes(group=group, fill=100*(prop_bush-overall_bush_prop))) +
scale_fill_gradient2(name="% Margin", low="blue", high="red", mid="white") +
geom_path(data=counties_map_tidy, aes(group=group), col="black", size=0.05) +
geom_path(data=states_map_tidy, aes(group=group), col="black", size=0.3) +
coord_map() +
labs(title="% Margin of Bush Victory Above/Below 49.7%")
# kMeans ------------------------------------------------------------------
# Prepare input data
input_data <- elections_county %>%
select(lat_centroid, long_centroid)
# Fit kMeans Clustering
k <- 2
results <- kmeans(input_data, k, nstart = 20)
# Look at results
results$cluster %>% table()
centers <- results$centers %>%
tbl_df()
centers
# Add cluster results to main data:
elections_county <- elections_county %>%
mutate(cluster = as.factor(results$cluster))
# Join with map data and plot
cluster_map <- counties_map_tidy %>%
inner_join(elections_county, by=c("id"="fips"))
ggplot(NULL, aes(x=long, y=lat)) +
geom_polygon(data=cluster_map, aes(group=group, fill=cluster)) +
# Trace outlines:
geom_path(data=counties_map_tidy, aes(group=group), col="black", size=0.05) +
geom_path(data=states_map_tidy, aes(group=group), col="black", size=0.3) +
coord_map() +
# This will only work if you included long_centroid and lat_centroid as X's:
geom_point(data=centers, aes(x=long_centroid, y=lat_centroid), size=3)
# Redo the above code but selecting
# -Different combinations of n, lat_centroid, long_centroid, pop_density,
# prop_bush, etc inside input_data
# -Different numbers of clusters k
install.packages("maptools")
library(tidyverse)
library(USAboundaries)
library(sp)
library(stringr)
library(broom)
# Load Counties Data -----------------------------------------------------------
# Data consists of observations for 3109 counties in 2000 election
# -(longitude, latitude) of county's centroid i.e. middle point
# -area_sqmi: surface area of county in square miles
# -bush/gore: number of votes for George W. Bush/Al Gore. Other candidates dropped for simplicity.
# -n=bush+gore. NOT the # of votes, but # for Bush + # for Gore
# -pop_density is not true (# of people)/area, but (# of Bush/Gore voters)/area.
elections_county <-
"https://raw.githubusercontent.com/rudeboybert/MATH218/gh-pages/assets/kMeans/elections_2000.csv" %>%
read_csv() %>%
mutate(pop_density = n/area_sqmi)
View(elections_county)
counties_map <- USAboundaries::us_counties("2000-11-01")
states_map <- USAboundaries::us_states("2000-11-01")
plot(counties_map, axes=TRUE)
plot(states_map, axes=TRUE)
# Let's plot in ggplot. broom::tidy() to the rescue!
counties_map_tidy <- counties_map %>%
# set id variable to be FIPS codes
tidy(region="fips") %>%
tbl_df() %>%
# Remove Alaska/Hawaii, who have FIPS codes 02 & 15
filter(!str_sub(id, 1, 2) %in% c("02", "15"))
states_map_tidy <- states_map %>%
tidy(region="abbr_name") %>%
tbl_df() %>%
# Remove Alaska/Hawaii
filter(!id %in% c("AK", "HI"))
ggplot(NULL, aes(x=long, y=lat)) +
# The group aesthetic ensures points in the same polygon are kept together:
geom_polygon(data=counties_map_tidy, aes(group=group), fill="white") +
# Trace outlines of counties then states:
geom_path(data=counties_map_tidy, aes(group=group), col="black", size=0.05) +
geom_path(data=states_map_tidy, aes(group=group), col="black", size=0.3) +
# Use correct aspect ratio for maps:
coord_map()
# Plot 2000 Electoral Map -----------------------------------------------------------
# Overall the lower 48 George W. Bush got 49.7% of vote
overall_bush_prop <- sum(elections_county$bush)/sum(elections_county$n)
elections_map <- counties_map_tidy %>%
inner_join(elections_county, by=c("id"="fips"))
ggplot(NULL, aes(x=long, y=lat)) +
# Fill in county polygons color-coded by %'age margin for push over 49.7%
geom_polygon(data=elections_map, aes(group=group, fill=100*(prop_bush-overall_bush_prop))) +
scale_fill_gradient2(name="% Margin", low="blue", high="red", mid="white") +
geom_path(data=counties_map_tidy, aes(group=group), col="black", size=0.05) +
geom_path(data=states_map_tidy, aes(group=group), col="black", size=0.3) +
coord_map() +
labs(title="% Margin of Bush Victory Above/Below 49.7%")
# kMeans ------------------------------------------------------------------
# Prepare input data
input_data <- elections_county %>%
select(lat_centroid, long_centroid)
# Fit kMeans Clustering
k <- 2
results <- kmeans(input_data, k, nstart = 20)
# Look at results
results$cluster %>% table()
centers <- results$centers %>%
tbl_df()
centers
# Add cluster results to main data:
elections_county <- elections_county %>%
mutate(cluster = as.factor(results$cluster))
# Join with map data and plot
cluster_map <- counties_map_tidy %>%
inner_join(elections_county, by=c("id"="fips"))
ggplot(NULL, aes(x=long, y=lat)) +
geom_polygon(data=cluster_map, aes(group=group, fill=cluster)) +
# Trace outlines:
geom_path(data=counties_map_tidy, aes(group=group), col="black", size=0.05) +
geom_path(data=states_map_tidy, aes(group=group), col="black", size=0.3) +
coord_map() +
# This will only work if you included long_centroid and lat_centroid as X's:
geom_point(data=centers, aes(x=long_centroid, y=lat_centroid), size=3)
# Redo the above code but selecting
# -Different combinations of n, lat_centroid, long_centroid, pop_density,
# prop_bush, etc inside input_data
# -Different numbers of clusters k
install.packages("rgeos")
library(tidyverse)
library(USAboundaries)
library(sp)
library(stringr)
library(broom)
library(maptools)
library(rgeos)
# Load Counties Data -----------------------------------------------------------
# Data consists of observations for 3109 counties in 2000 election
# -(longitude, latitude) of county's centroid i.e. middle point
# -area_sqmi: surface area of county in square miles
# -bush/gore: number of votes for George W. Bush/Al Gore. Other candidates dropped for simplicity.
# -n=bush+gore. NOT the # of votes, but # for Bush + # for Gore
# -pop_density is not true (# of people)/area, but (# of Bush/Gore voters)/area.
elections_county <-
"https://raw.githubusercontent.com/rudeboybert/MATH218/gh-pages/assets/kMeans/elections_2000.csv" %>%
read_csv() %>%
mutate(pop_density = n/area_sqmi)
View(elections_county)
counties_map <- USAboundaries::us_counties("2000-11-01")
states_map <- USAboundaries::us_states("2000-11-01")
plot(counties_map, axes=TRUE)
plot(states_map, axes=TRUE)
# Let's plot in ggplot. broom::tidy() to the rescue!
counties_map_tidy <- counties_map %>%
# set id variable to be FIPS codes
tidy(region="fips") %>%
tbl_df() %>%
# Remove Alaska/Hawaii, who have FIPS codes 02 & 15
filter(!str_sub(id, 1, 2) %in% c("02", "15"))
states_map_tidy <- states_map %>%
tidy(region="abbr_name") %>%
tbl_df() %>%
# Remove Alaska/Hawaii
filter(!id %in% c("AK", "HI"))
ggplot(NULL, aes(x=long, y=lat)) +
# The group aesthetic ensures points in the same polygon are kept together:
geom_polygon(data=counties_map_tidy, aes(group=group), fill="white") +
# Trace outlines of counties then states:
geom_path(data=counties_map_tidy, aes(group=group), col="black", size=0.05) +
geom_path(data=states_map_tidy, aes(group=group), col="black", size=0.3) +
# Use correct aspect ratio for maps:
coord_map()
# Plot 2000 Electoral Map -----------------------------------------------------------
# Overall the lower 48 George W. Bush got 49.7% of vote
overall_bush_prop <- sum(elections_county$bush)/sum(elections_county$n)
elections_map <- counties_map_tidy %>%
inner_join(elections_county, by=c("id"="fips"))
ggplot(NULL, aes(x=long, y=lat)) +
# Fill in county polygons color-coded by %'age margin for push over 49.7%
geom_polygon(data=elections_map, aes(group=group, fill=100*(prop_bush-overall_bush_prop))) +
scale_fill_gradient2(name="% Margin", low="blue", high="red", mid="white") +
geom_path(data=counties_map_tidy, aes(group=group), col="black", size=0.05) +
geom_path(data=states_map_tidy, aes(group=group), col="black", size=0.3) +
coord_map() +
labs(title="% Margin of Bush Victory Above/Below 49.7%")
# kMeans ------------------------------------------------------------------
# Prepare input data
input_data <- elections_county %>%
select(lat_centroid, long_centroid)
# Fit kMeans Clustering
k <- 2
results <- kmeans(input_data, k, nstart = 20)
# Look at results
results$cluster %>% table()
centers <- results$centers %>%
tbl_df()
centers
# Add cluster results to main data:
elections_county <- elections_county %>%
mutate(cluster = as.factor(results$cluster))
# Join with map data and plot
cluster_map <- counties_map_tidy %>%
inner_join(elections_county, by=c("id"="fips"))
ggplot(NULL, aes(x=long, y=lat)) +
geom_polygon(data=cluster_map, aes(group=group, fill=cluster)) +
# Trace outlines:
geom_path(data=counties_map_tidy, aes(group=group), col="black", size=0.05) +
geom_path(data=states_map_tidy, aes(group=group), col="black", size=0.3) +
coord_map() +
# This will only work if you included long_centroid and lat_centroid as X's:
geom_point(data=centers, aes(x=long_centroid, y=lat_centroid), size=3)
# Redo the above code but selecting
# -Different combinations of n, lat_centroid, long_centroid, pop_density,
# prop_bush, etc inside input_data
# -Different numbers of clusters k
library(tidyverse)
library(broom)
library(lubridate)
#sexy themes
#install.packages('ggthemes')
library(ggthemes)
library(glmnet)
install.packages('bisoreg')
library(bisoreg)
# 2. Load Data Files & Data Cleaning --------------------------------------
#The working directory. Make sure to modify it when you run your code
setwd("~/Desktop/Junior Spring/Statistical Learning/Homework/Final/Team_F")
train <- read_csv("Files/train.csv")
test <- read_csv("Files/test.csv")
sample_submissions <- read_csv("Files/sample_submission.csv")
#supplemetal information about the stores:
store <- read_csv("Files/store.csv")
#since the store info is relevant to both train and test datasets let's join them to the datasets
train <- left_join(train,store, by="Store")
test <- left_join(test,store,by="Store")
#Since the dataset is too big, I couldn't do proper conputations so I am going to select a subset
train <- train %>%
sample_frac(0.1) %>%
mutate(Year=year(Date), Month=month(Date), DayOfMonth=day(Date))
test <- test %>%
mutate(Year=year(Date), Month=month(Date), DayOfMonth=day(Date))
cv_loess <- loess.wrapper(train$Sales, train$CompetitionDistance, span.vals = seq(0, 1, by = 0.5), folds = 2)
cv_loess <- loess.wrapper(train$Sales, train$CompetitionDistance, span.vals = seq(0.1, 1, by = 0.4), folds = 2)
cv_loess <- loess.wrapper(train$Sales, train$CompetitionDistance, span.vals = seq(0.3, 1, by = 0.4), folds = 2)
cv_loess <- loess.wrapper(train$Sales, train$CompetitionDistance, span.vals = seq(0.3, 1, by = 0.4), folds = 2)
View(train)
model_formula <- train %>%
# Take all predictor variable names and separate them with + signs:
names() %>%
setdiff(c("Id", "CompetitionDistance", "Promo")) %>%
stringr::str_c(collapse=" + ") %>%
# Add outcome variable and ~ sign and convert to formula
stringr::str_c("Sales ~ ", .)
model_formula
model_formula <- as.formula(model_formula)
model_formula
View(train)
View(train)
model_formula <- train %>%
# Take all predictor variable names and separate them with + signs:
names() %>%
setdiff(c("Id", "Sales", "Customers", "Date","PromoInterval")) %>%
stringr::str_c(collapse=" + ") %>%
# Add outcome variable and ~ sign and convert to formula
stringr::str_c("SalePrice ~ ", .)
model_formula
model_formula <- as.formula(model_formula)
X <- model.matrix(model_formula, data = train)[, -1]
y <- train$Sales
model_formula <- train %>%
# Take all predictor variable names and separate them with + signs:
names() %>%
setdiff(c("Id", "Sales", "Customers", "Date","PromoInterval")) %>%
stringr::str_c(collapse=" + ") %>%
# Add outcome variable and ~ sign and convert to formula
stringr::str_c("Sales ~ ", .)
model_formula
model_formula <- as.formula(model_formula)
X <- model.matrix(model_formula, data = train)[, -1]
y <- train$Sales
model_ridge <- glmnet(X, y, alpha = 0, lambda = 3)
X <- model.matrix(model_formula, data = train)[, -1]
View(X)
model_ridge <- glmnet(X, y, alpha = 0, lambda = 3)
model_formula
model_formula <- Sales ~ Store + DayOfWeek + Promo + CompetitionDistance
X <- model.matrix(model_formula, data = train)[, -1]
y <- train$Sales
model_ridge <- glmnet(X, y, alpha = 0, lambda = 3)
X <- model.matrix(model_formula, data = train)
y <- train$Sales
model_ridge <- glmnet(X, y, alpha = 0, lambda = 3)
train_fill <- train %>% mutate(CompetitionDistance2 = ifelse(is.na(CompetitionDistance), 0, CompetitionDistance))
model_formula <- Sales ~ Store + CompetitionDistance2
X <- model.matrix(model_formula, data = train_fill)[, -1]
y <- train_fill$Sales
model_ridge <- glmnet(X, y, alpha = 0, lambda = 3)
test_X <- model.matrix(model_formula, data = test)[, -1]
model_formula <- Store + CompetitionDistance
model_formula <- Sales ~ Store + CompetitionDistance
model_formula <- ~ Store + CompetitionDistance
test_X <- model.matrix(model_formula, data = test)[, -1]
predictions <- model_ridge %>%
predict(newx=test_X, s=lambda_star_ridge) %>%
as.vector()
predictions <- model_ridge %>%
predict(newx=test_X, s=3) %>%
as.vector()
predictions
View(sample_submissions)
sample_submission %>%
mutate(Sales = as.vector(predictions))
sample_submissions %>%
mutate(Sales = as.vector(predictions))
predictions <- model_ridge %>%
predict(newx=test_X, s=3) %>%
as.vector()
sample_submissions %>%
mutate(Sales = as.vector(predictions))
model_formula <- Sales ~ Store + CompetitionDistance2
X <- model.matrix(model_formula, data = train_fill)[, -1]
y <- train_fill$Sales
model_ridge <- glmnet(X, y, alpha = 0, lambda = 3)
model_formula <- ~ Store + CompetitionDistance
test_X <- model.matrix(model_formula, data = test)[, -1]
predictions <- model_ridge %>%
predict(newx=test_X, s=3) %>%
as.vector()
sample_submissions %>%
mutate(Sales = as.vector(predictions))
model_formula <- Sales ~ Store + CompetitionDistance2
X <- model.matrix(model_formula, data = train_fill)[, -1]
y <- train_fill$Sales
model_ridge <- glmnet(X, y, alpha = 0, lambda = 3)
model_formula <- ~ Store + CompetitionDistance2
test_X <- model.matrix(model_formula, data = test_fill)[, -1]
predictions <- model_ridge %>%
predict(newx=test_X, s=3) %>%
as.vector()
sample_submissions %>%
mutate(Sales = as.vector(predictions))
model_formula <- Sales ~ Store + CompetitionDistance2
X <- model.matrix(model_formula, data = train_fill)[, -1]
y <- train_fill$Sales
model_formula <- ~ Store + CompetitionDistance2
test_X <- model.matrix(model_formula, data = test_fill)[, -1]
test_fill <- test %>% mutate(CompetitionDistance2 = ifelse(is.na(CompetitionDistance), 0, CompetitionDistance))
test_X <- model.matrix(model_formula, data = test_fill)[, -1]
predictions <- model_ridge %>%
predict(newx=test_X, s=3) %>%
as.vector()
sample_submissions %>%
mutate(Sales = as.vector(predictions))
#Section E
#LASSO
model_formula <- Sales ~ Store + CompetitionDistance2
X <- model.matrix(model_formula, data = train_fill)[, -1]
y <- train_fill$Sales
model_ridge <- glmnet(X, y, alpha = 1, lambda = 3)
model_formula <- ~ Store + CompetitionDistance2
test_X <- model.matrix(model_formula, data = test_fill)[, -1]
predictions <- model_ridge %>%
predict(newx=test_X, s=3) %>%
as.vector()
sample_submissions %>%
mutate(Sales = as.vector(predictions))
library(tidyverse)
library(broom)
library(lubridate)
#sexy themes
#install.packages('ggthemes')
library(ggthemes)
library(glmnet)
install.packages('bisoreg')
library(bisoreg)
# 2. Load Data Files & Data Cleaning --------------------------------------
#The working directory. Make sure to modify it when you run your code
setwd("~/Desktop/Junior Spring/Statistical Learning/Homework/Final/Team_F")
train <- read_csv("Files/train.csv")
test <- read_csv("Files/test.csv")
sample_submissions <- read_csv("Files/sample_submission.csv")
#supplemetal information about the stores:
store <- read_csv("Files/store.csv")
#since the store info is relevant to both train and test datasets let's join them to the datasets
train <- left_join(train,store, by="Store")
test <- left_join(test,store,by="Store")
#Since the dataset is too big, I couldn't do proper conputations so I am going to select a subset
train <- train %>%
sample_frac(0.1) %>%
mutate(Year=year(Date), Month=month(Date), DayOfMonth=day(Date))
test <- test %>%
mutate(Year=year(Date), Month=month(Date), DayOfMonth=day(Date))
